import pandas as pd
from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt

df = pd.read_csv("combined_results.csv")
df["binary_label"] = df["label"].apply(lambda x: 1 if x == "fake" else 0)

methods = ["entropy", "fourier", "color", "metadata", "artifacts"]

print("\nðŸ“Š ÐžÑ†ÐµÐ½ÐºÐ° ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð²:")
for method in methods:
    auc = roc_auc_score(df["binary_label"], df[method])
    threshold = 0.5  # Ð¼Ð¾Ð¶Ð½Ð¾ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾ Ð¸ÑÐºÐ°Ñ‚ÑŒ best threshold
    pred = (df[method] >= threshold).astype(int)
    acc = accuracy_score(df["binary_label"], pred)
    f1 = f1_score(df["binary_label"], pred)
    print(f"ðŸ”¹ {method.upper()}: AUC={auc:.3f}, Accuracy={acc:.3f}, F1={f1:.3f}")

# ROC-Ð³Ñ€Ð°Ñ„Ð¸Ðº
from sklearn.metrics import roc_curve

plt.figure(figsize=(8, 6))
for method in methods:
    fpr, tpr, _ = roc_curve(df["binary_label"], df[method])
    auc = roc_auc_score(df["binary_label"], df[method])
    plt.plot(fpr, tpr, label=f"{method} (AUC={auc:.2f})")

plt.plot([0, 1], [0, 1], "k--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC-ÐºÑ€Ð¸Ð²Ñ‹Ðµ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð²")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
