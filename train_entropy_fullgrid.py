import os
import numpy as np
import pandas as pd
from The_entropy_complexity_method import analyze_entropy_complexity_raw
from sklearn.metrics import roc_auc_score
from tqdm import tqdm

folders = {
    'real_phone': 'real_phone',
    'real_net': 'real_net',
    'fake': 'fake'
}

raw_data = []

# === –°–±–æ—Ä —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–∞–∂–¥–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é ===
print("üì• –°–±–æ—Ä –∑–Ω–∞—á–µ–Ω–∏–π...")
for label, path in folders.items():
    for fname in os.listdir(path):
        if fname.lower().endswith(('.jpg', '.jpeg', '.png')):
            fpath = os.path.join(path, fname)
            try:
                for tolerance in [0.10, 0.15, 0.20]:
                    for radius in [5, 7, 9]:
                        raw = analyze_entropy_complexity_raw(fpath, radius=radius, tolerance=tolerance)
                        raw_data.append({
                            "filename": fname,
                            "label": label,
                            "binary_label": 1 if label == "fake" else 0,
                            "tolerance": tolerance,
                            "radius": radius,
                            "mean_cluster_size": raw
                        })
            except Exception as e:
                print(f"‚ùå {fname}: {e}")

df_raw = pd.DataFrame(raw_data)

# === –û–±—É—á–∞–µ–º min_size –∏ max_size –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ—á–µ—Ç–∞–Ω–∏—è radius + tolerance ===
print("‚öôÔ∏è –ü–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
results = []

for (tol, rad), group in tqdm(df_raw.groupby(["tolerance", "radius"])):
    for min_s in range(10, 100, 5):
        for max_s in range(min_s + 50, 400, 10):
            scaled = 1 - np.clip((group["mean_cluster_size"] - min_s) / (max_s - min_s), 0, 1)
            auc = roc_auc_score(group["binary_label"], scaled)
            results.append({
                "tolerance": tol,
                "radius": rad,
                "min_size": min_s,
                "max_size": max_s,
                "AUC": auc
            })

df_results = pd.DataFrame(results)
best_row = df_results.loc[df_results["AUC"].idxmax()]

print("\nüèÜ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:")
print(best_row)

# === –°–æ—Ö—Ä–∞–Ω–∏–º –≤—Å—ë –≤ —Ç–∞–±–ª–∏—Ü—É
df_results.to_csv("entropy_grid_full_results.csv", index=False)

# === –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ JSON
import json
with open("best_entropy_params.json", "w") as f:
    json.dump({
        "tolerance": float(best_row["tolerance"]),
        "radius": int(best_row["radius"]),
        "min_size": int(best_row["min_size"]),
        "max_size": int(best_row["max_size"])
    }, f, indent=4)

print("‚úÖ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ best_entropy_params.json")

